\section{Approach}\label{sec:approach}

\subsection{Syntax Scope and Grounder Simplifications}

%
\begin{itemize}
  \item
  We consider disyunctive ground logic programs with choice rules under the answer set semantics.
  %
  \item This is to avoid the simplifications that grounders do, which can be hard to track back to the original program.
  \item One of the reason for this simplifications is to have a simple normal form that can be interpreted by the solver.
  %
  \item This normal form allows disjunction or choices in the head, and either a sum aggregate with a lower bound or a conjunction of literals in the body.
  \cite{kamrom23a} \comment{S: perhaps there is a better reference for this? but I am not sure}
  \item To transform all available constructs in clingo into this normal form, the grounder introduces auxiliary atoms.
  \item This means that we will get auxiliary atoms when using
  $\#sum$ or $\#count$ aggregates, as well as
  anonymous variables,
  conditional literals,
  and choice rules with bounds or conditional literals within them.
  \item Furthermore, we do not consider sum aggregates, as this would require a more complex graph with weighted edges, and a special type of node to sum them up.
  \item We don't consider double negation.
  %
\end{itemize}
%

\subsection{Labeled Logic Programs}
\label{sec:labeled-logic-programs}

%
\begin{itemize}
  \item We refer to labelled logic programs because the program graph gives IDs to the bodies.
\end{itemize}
%

%
\paragraph{Labelled Ground Disjunctive programs}
A \emph{(labelled) rule} is an implication either of the form
\begin{eqnarray}
  \ell : p_1 \vee \dots \vee p_m \leftarrow q_1 \wedge \dots \wedge q_n \wedge \neg s_1 \wedge \dots \wedge \neg s_j \label{f:disjunctive-rule}
\end{eqnarray}
%
or of the form
%
\begin{eqnarray}
  \ell : \{p_1;\ \dots;\ p_m\} \leftarrow q_1 \wedge \dots \wedge q_n \wedge \neg s_1 \wedge \dots \wedge \neg s_j \label{f:choice-rule}
\end{eqnarray}
where $m, n, j \in \mathbb{N}_0$ (i.e., non-negative integers),
%
For any of the forms \eqref{f:disjunctive-rule} and \eqref{f:choice-rule}, we use $\Bd{r}$ and $\Hd{r}$ to refer to the \emph{antecedent} and the \emph{consequent} of the implication respectively.
%
We denote the set of atoms in the head of $r$ as
$\HH{r} \eqdef \{p_1, \dots, p_m\}$ in the case of rules of the form \eqref{f:disjunctive-rule}
and as $\HH{r} \eqdef \{a_1, \dots, a_k\}$ in the case of rules of the form \eqref{f:choice-rule}.
%
The set of atoms in the positive body are represented as
$\BB{r} \eqdef \{q_1,\dots,q_n\}$
and
the set of atoms in the negative body are represented as
$\BBn{r} \eqdef \{s_1,\dots,s_n\}$.
%
A \emph{(labelled) logic program} is a set of labelled rules.
%
Note that given any logic program $P$, we can get a labelled logic program by simply labelling each rule with an incremental identifier.
%
Given a rule $r$ like \eqref{f:disjunctive-rule} or \eqref{f:choice-rule}, we denote its label as $\Lb{r}\eqdef \ell$,
%
and so, we denote the rule $r$ corresponding to a label $\ell$ as $\InvLb{\ell}$.
%
Finally, we denote $\Lbs{P} \eqdef \{ \Lb{r} \mid r \in P \}$ as the set of all labels of the rules in a labelled program $P$.
\medskip
\comment{S: Brais will change this to all be sets.}
%
$\isdisj{r}$: denotes that rule $r$'s head is a disjunction, that is, a rule of the form \eqref{f:disjunctive-rule}.
$\iscons{r}$: denotes that a disjunctive rule $r$'s head is empty, that is, a constraint rule.
$\ischoice{r}$: denotes that rule $r$'s head is a choice, that is, a rule of the form \eqref{f:choice-rule}.
$\atoms{P}$ is the set of all the atoms occuring in $P$.
%


\subsection{Program Graph}
\label{sec:program-graph}

\comment{I am worried about this graph definition,
because if you have a program graph $\langle V, E \rangle$ then we can't know the types of nodes and edges.
Perhaps having $\pg{P} = \langle (\Vc , \Vd , \Va), (\Epos , \Eneg) \rangle$?}
%
\begin{definition}[Program Graph]
%
Given a labelled logic program $P$, its corresponding \emph{program graph} is a directed graph
$\pg{P} = \langle \Vc \cup \Vd \cup \Va, \Epos \cup \Eneg \rangle$
where
%
$\Vc$, $\Vd$ and $\Va$ are nodes in the graph following the definitions below:
\begin{itemize}
    \item $\Vd = \{ \Lb{r} \mid r \in P \land (\isdisj{r} \vee \iscons{r})      \}$ is the set of rules's labels, whose head is a dijunction;
    \item $\Vc = \{ \Lb{r} \mid r \in P \land \ischoice{r}    \}$ is the set of rules's labels, whose head is a choice;
    \item $\Va = \{ a      \mid a \in \atoms{P} \}$ is the set atoms which occur within any head of any rule in $P$.
\end{itemize}

and $\Epos$ and $\Eneg$ are the sets of edges of the graph such that:
\begin{itemize}
  \item $\forall r \in P, \forall a \in \BB{r}  \rightarrow (a,\Lb{r})  \in \Epos$
  \item $\forall r \in P, \forall a \in \BBn{r} \rightarrow (a, \Lb{r}) \in \Eneg$
  \item $\forall r \in P, \forall h \in \HH{r}  \rightarrow (\Lb{r}, h) \in \Epos$
\end{itemize}
%
\end{definition}
%



\paragraph{Discussion points}
\begin{itemize}
  \item
  A program graph is a directed graph that syntactically represents a logic program,
  capturing all details specified by the ASP developer.
  It serves as the foundational structure for generating explanations.
\end{itemize}

%
\begin{example}[Program Graph]\label{ex:example1}
  This is a modified version of the James Bond example from Fandinno
  A drug $d$ in James Bond’s drink causes his paralysis $p$
  \comment{ırais will fix this example and add reference}
  provided that he was not given an antidote $a$ that day.
  We know that Bond’s enemy, Dr. No, poured the drug. He gets the antidote if he is not on holiday $h$.
  Unlike in the original example, we add $w$ to indicate a working day,
  and a choice to decide if James is on holiday or working,
  where the constraints in rules 2 and 3 ensuring exactly one of them is true.
  \comment{Note that adding the choice with bounds would have introduced auxiliary atoms as explained before, and would not be part of our restricted input.}
  %%
  \lstinputlisting[caption={Modified James Bond Example. Program $P1$}, language=clingos, label={lst:example1}]{encodings/example1.lp}
  %%
  $P1$ has two models, namely $\m_1 = \{w, d, a\}$ and $\m_2 = \{h, d, p\}$,
  where James is not poisoned in $\m_1$ since he is working and gets the antidote, and he is poisoned in $\m_2$ since he is on holiday and does not get the antidote.
  %
  Figure~\ref{fig:program-graph} shows the program graph corresponding to program $P1$.
  %
  \begin{figure}
    \centering
    % \includegraphics[width=0.75\textwidth]{resources/program-graph.png}
    % \includesvg[width=\textwidth]{resources/pg.svg}   %%% fails to scale text: asplain's or latex's problem?
    \includegraphics[scale=0.05]{resources/pg.png}
    \label{fig:program-graph}
    \caption{Program graph $G_{P_{1}}$ corresponding to program in Listing~\ref{lst:example1}. }
  \end{figure}\comment{What do we do with optional nodes, that is abduction...}
  %
  Circle-nodes in graph $G_{P_{1}}$ represent atoms appearing in $P1$, that is, the set $\Va = \{d,a,h,w,p\}$.
  %
  Rectangle-nodes in graph $G_{P_{1}}$ represent the body of some rule in $P1$, in particular, sets $\Vc = \{r1\}$
  and $\Vd = \{r2,r3,r4,r5,r6\}$ correspond to the set of rules in $P1$ whose head is a choice, respectively a disjunction.
  %
  Edges in $E^{+}$ are represented by solid arrows, while edges in $E^{-}$ are represented by dashed arrows.
  Edges from atoms to rules correspond to positive and negative literals.

  % For any atom (circle-node) $a \in \Vc$ for which it exists some rule $r$
  % for which $a \in \HH(r)$, it must exist a solid edge $(r,a) \in E^{+}$.
  % %
  % For any atom (or circle-node) $a \in \Vc$ for which it exists some rule $r$ for which $a \in \BB{r}$ (or respectively $a \in \BBn{r}$), it must exist a solid (respectively dashed) edge $(a,r) \in E^{+}$ (or respectively $(a,r) \in E^{-}$).
  % %

  %
  Note how, as expected, facts are depicted in the graphs as square nodes without any incoming edge, while constraints are depicted as square nodes without any outgoing edge.
  %
\end{example}


\begin{proposition}
  If two programs have the same program graph, they are strongly equivalent.
\end{proposition}
%

\begin{proposition}
  Given two labelled disyunctive, ground programs $P1$ and $P2$ and their respective program graphs $\pg{P1}$ and $\pg{P2}$, then
  \[ \pg{P1} = \pg{P2} \rightarrow P1 = P2 \]
\end{proposition}


%%%%%%%%%%%%%%%%%%% EXPLAINING MODELS

\subsection{Explaining a model: Model Subgraph}
\label{sec:model-subgraph}

\begin{definition}[Model Subgraph from Model]
  Given a program graph $\pg{P} = \langle \Vc \cup \Vd \cup \Va, \Epos \cup \Eneg \rangle$,
  and an answer set $\m \subseteq \Va$ of $P$,
  a \emph{model subgraph} is a pair $\mgpi{P}{\m} = \langle V, E \rangle$ such that
  \begin{itemize}
    % take all the atoms in the model as nodes and all the supported rules as nodes as welll
    \item $V = \m \cup \{ \Lb{r} \mid r \in P \land \m \models \Bd{r} \}$
    % any join all the included nodes using positive edges only
    \item $E = \{ (v_1, v_2) \mid (v_1, v_2 \in V)\ \land\ (v_1, v_2) \in \Epos  \}$
  \end{itemize}
\end{definition}

%
\begin{proposition}
  Given a program $P$ and a model $\m$ of $P$,
  the \emph{model subgraph} $MG_P^\m$ is a subgraph of the \emph{program graph} $\pg{P}$.
\end{proposition}
%
\begin{figure}
  \centering
  \includegraphics[scale=0.05]{resources/foil.png}
  \caption{Visualization of model subgraph $\mgpi{P1}{\m_1}$.}
  \label{fig:model-subgraph}
\end{figure}


\paragraph{Discussion Points}
\begin{itemize}
  \item Intuition: we use a given model to extract a subgraph from the program graph,
  that highlights (1) supportiveness of atoms in the model; (2) supportiveness of rules; and (3) the truthness of the positive literals in the body.
  \item Negative edges are not included in the model subgraph
  since their origin atom would not be in the model and thus not part of the model subgraph.
  \item To include the information of negative literals in an explanation, we can compare the model subgraph with the program graph.
  This comparison is relevant as it gives us the information to provide causal explanations which include negative implications.
  \item
  A visualization example for $\mgpi{P1}{\m_1}$ with is shown in Figure~\ref{fig:model-subgraph}.
  We show the program graph $\pg{P}$ in the background, and highlight the model subgraph $\mgpi{P}{\m}$ for the given model $\m$ on top of it.
  As such, atoms are colored if they appear in the model and
  rules are colored if their body is supported by the model.
  Edges for positive literals are highlighted if they are satisfied by the model.
  While edges from rules to atoms are highlighted if the atom is in the model, indicating that it could be derivated by that supported rule.
  \item Notice, does not select any particular derivation when alternative causes emerge.
  (that is, is not causal) (is not equivalent to \cite{cabmun24a} but could be equivalent to \cite{altrsoba23a})
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%% ABDUCTION

\subsection{Abduction for Explanation}
\label{sec:abductive-explanations}

%       Extended version
% \paragraph{Context and Motivation}
% \begin{itemize}
%   \item Contrastivness is one of the main properties of human explanations~\cite{miller19}.
%   %
%   \item First, explanation-asking question (or queries) from humans are often contrastive, which means that they ask for some event that is not true in a world or scenario that is taken as reference.
%   %
%   \item To put an example, a typical human question/query would be \textit{Why isn't James posioned?}, implying a the existence of a scenario where James is not poisoned and that the asking human is taking as a reference.
%   %
%   \item In the real world, this reference world is normally a particular interpretation of the asking human about some events that she perceived.
%   %
%   \item A valid human contrastive explanation to that query will have to contrast the reference scenario with an alternative one where the question previously made is positively answered.
%   %
%   \item This alternative or hypothetical world is reffered in literature as \emph{foil}, whereas the reference world is reffered as \emph{fact}.
%   %
% \end{itemize}

\paragraph{Context and Motivation}
\begin{itemize}
  %
  \item Humans usually ask for explanations when they expect some event, but are exposed to a different outcome/situation instead.
  %
  \item People ask “why not” questions relative to a reference and hypothetical/alternative scenarios.
  %
  \item Example: \textit{Why isn’t James poisoned?} — the asker \emph{assumes} or \emph{expects} a hypothetical world where James is poisoned.
  %
  \item This expectation is called \emph{foil} or \emph{foil world} in the literature, whereas the \emph{reference world} or \emph{fact world} is the asker’s interpretation of observed events where James is not poioned.
  \comment{Brais will re-think these terms to make them more clear and consistent.}
  %
  \item In ASP context, this happens, for instance, when the users expects something that does not happen in the shown solution.
  %
  \item Examples:
  \begin{itemize}
    \item User expected $a$ to be in the answer, but it's not.
    \item User expected $a$ not to be in the answer, but it is.
    \item User expected $a$ to be in the answer, but there is no answer (UNSAT).
  \end{itemize}
  %
  \item Abduction is the process we refer to find the \emph{foil answer} that satisfies the query.
  \comment{S: Below we have foil pair, and just foil, I think we need to clearly distinguish this.
  The bellow it would be "an a foil answer set ...".
  In this part I guess foil world would be the \pf and foil answer set would be $\m_f$? }
  %
  \item However, other processes could be used to find a valid \emph{foil answer}, and we may study its relation with our notion of abduction.
  \comment{S: What kind of process?}
\end{itemize}
%

\paragraph{Assumptions}
\begin{itemize}
  %
  \item We start from a \emph{reference} program $\pr$.
  %
  \item Query $Q$ is a set of literals.
  %
  \item \emph{Abduction} is the process of finding a \emph{foil program} $\pf$ and an answer set $\m_f$ of $\pf$ such that $\m_f \models Q$.
  %
  \item The way we obtain $\pf$ and $\m_f$ is by adding and removing rules from $\pr$ in a controlled way.
  %
\end{itemize}
%

%
\begin{definition}[Valid Foil]\label{def:valid-foil}
  Given
  \begin{itemize}
    %
    \item a set of literals $Q$ refered as \emph{query},
    %
    \item a \emph{reference program} $\pr$,
    %
    \item a set of \emph{removable} labelled rules $\removable \subseteq \pr$
    \DEL{of the form \eqref{f:disjunctive-rule} and \eqref{f:choice-rule}},
    \comment{If we say the the vertex are labels then these should also be labels?}
    %
    \item and
    %
    \item a set of \emph{addable} labelled rules $\addable$ \DEL{of the form \eqref{f:disjunctive-rule} and \eqref{f:choice-rule}},
    %
  \end{itemize}
  %
  % we say the model subgraph $MG_{\pf}^{\m_f}$
  we say the pair $(\pf, \m_f)$
  is a \emph{valid foil for $\pr$ with respect to some $\addable$, $\removable$ and $Q$} iff:
  \begin{itemize}
    \item $ \pr \setminus \removable \subseteq \pf \subseteq (\pr \cup \addable)$
    \item $\m_f \in AS(\pf)\ \land\ \m_f \models Q$
    \comment{Make sure AS is well defined before.}
  \end{itemize}
  Additionally, we denote $\foils(\pr, \addable, \removable, Q)$ as the set of \emph{all valid foils for $\pr$ with respect to $\addable$, $\removable$, and $Q$}.
\end{definition}
%
\paragraph{Discussion on Valid Foil (Def. \ref{def:valid-foil})}
\begin{itemize}
  \item Intuitively, for obtaining a valid foil you can take $\pr$, and you may add/remove anything from $\addable$ and $\removable$ to obtain a new foil program $\pf$. For any model $\m_f$ of $\pf$ that satisfies the query $Q$, you can form a valid foil.
  %
  \item Also, note that $\pf$ may be equal to $\pr$ meaning that we did not add or remove anything from $\pr$ and we still find a $\m_f$ model that satisfies the query. That is, there was another model of $\pr$ that satisfy the query and can be used to explain \emph{why not} $Q$.
  %
  \item In the case that the set $\foils(\pr, \addable, \removable, Q) = \emptyset$, this means that there is no way to satisfy the query even if removing or adding any combination from $\removable$ or $\addable$.
  %
  \item Of course, note that there is no restrictions over both the $\removable$ or $\addable$ sets, which means that one could put potentially anything there. Therefore, some $\addable$ or $\removable$ sets can be weird.
  \begin{itemize}
    \item For instance, adding rules which do not interact at all with the rest of rules in $\pr$ (they do not share language).
  \end{itemize}
  %
  % \item Regarding contrastive explanations, from a \emph{reference program} and a query $Q$, the idea is to find a \emph{foil valid subgraph} $MG_{\pf}^{\m_f}$ with with respect to $Q$, that will be later used to compute a contrast graph $CG_{\pr, \pf}^{\m_r, \m_f}$.
  %
  \item {\color{blue} This definition does not impose the existence of a \emph{reference model} $\m_r \models \pr$}
  This allows finding foils for unsatisfiable reference programs, $AS(\pr) = \emptyset$.
  If $Q = \emptyset$ then we are simply recovering satisfiability.
  Otherwise, if $Q \neq \emptyset$, we are recovering satisfiability and forcing something to be true in the process.
  \item {\color{blue} This definition does not impose that $\m_r \nvDash Q$.}
  Therefore, the reference and foil models may collide $\m_r = \m_f$,
  which means that we are in fact doing no contrast.
  In other words, $\m_r$ already satisfy the query.
  Analyzing the the model subgraph $\mgpi{\pr}{\m_r}$ in comparison to $\pg{P}$,
  can then provide a causal explanation for \emph{why} $Q$.
  \comment{S: This would be like the other approaches, right brais?}
  %
  \item The sets $\removable$ and $\addable$ is what we informally call them \emph{abducibles}, that is, rules that we can add or remove to the original program in order to satisfy the query.
  %
  \item The most natural example of the abducibles is \emph{user input}, but any other notion can be abducible if it makes sense for the application.
  \item For instance, one could set the removable rules as all constraints, $\removable=\{r \mid r\in P\wedge\iscons{r}\}$, for debugging purposes to find out why the program is unsatisfiable.
  %$
  \item The set $\removable$ (\emph{removables}) is restricted to be a subset of $\pr$, while the set $\addable$ (\emph{addables}) is free, since we want to give full flexibility.
  %
  \item The idea is that they are defined for each use-case: the scope will be given as part of the domain, as user preference, as a programmer criteria, etc.
  %
  % \item There exist two important sets that are not needed in the definition, those are:
  % \comment{We add this sets here but latter on when defining a cost there is no reference to them, are they really relevant then?, I think we can just remove this part here}
  % \begin{itemize}
  %   %
  %   \item $\added = \pf \setminus \pr \subseteq \addable$, that is, the set of rules that were \emph{added}.
  %   %
  %   \item $\removed = \pr \setminus \pf \subseteq \removable$, that is, the set of rules that were \emph{removed}.
  %   %
  %   \item $\added$ and $\removed$ will play an important role when designing and implementing good explanation preferences.
  % \end{itemize}

\end{itemize}
%

\begin{example}[Abduction]\label{ex:example2}
  Consider $P2$ as the extension of $P1$ with the following rule which ensures that James is on holiday.
  \comment{S: This rule works like an assumption which can be a user input}
  \begin{lstlisting}[language=clingos]
    r7: :- not h.
  \end{lstlisting}

  % %
  % Recall $P$\ref{lst:example1} from Example~\ref{ex:example1}, and consider $P$\ref{lst:example2}, which only adds rule $7$, forcing to be a holiday.
  % %
  % \lstinputlisting[caption={Program $P$\ref{lst:example2}}, label={lst:example2}]{encodings/example2.lp}
  % %
  Now, imagine that a user is shown $P2$'s unique model $\m_2$,
  and let's say that they are surprised that James is poisoned and want to know why.
  To answer the question we can preform abduction by calculating $\foils(P2, \emptyset, \{r6, r7\}, \{ \neg p \})$,
  % where $Q = \{ \neg p \}$ which is the expected outcome from the user's point of view,
  % $\removable = $ and $\addable = \emptyset$.
  This yields four valid foils that satisfy the query, namely,
  $(P2\setminus \{r7\}, \{w, d, a\})$,
  $(P2\setminus \{r6\}, \{h\})$,
  $(P2\setminus \{r6, r7\}, \{h\})$ and
  $(P2\setminus \{r6, r7\}, \{w, a\})$.
  These foils can be visualized using their corresponding model subgraphs as shown in Figure~\ref{fig:foils}.
  %
  We use the color green to highlight foil models to latter distinguish them from the reference model.

\end{example}
%
\begin{figure}
  \centering
  \begin{tabular}{cc}
    \includegraphics[scale=0.05]{resources/f1.png} &
    \includegraphics[scale=0.05]{resources/f2.png} \\
    \includegraphics[scale=0.05]{resources/f3.png} &
    \includegraphics[scale=0.05]{resources/f4.png} \\
  \end{tabular}
  \caption{Visualizations of the four valid foils for $P2$ in Example~\ref{ex:example2}.
  Top figures remove rule $7$ (left) and rule $6$ (right).
  Bottom figures remove both rules, with different models.}
  \label{fig:foils}
\end{figure}


% \subsubsection{Abduction for unsat instances}



% \begin{example}[Abduction for UNSAT]\label{ex:example3}
%   %
%   Let us consider the \emph{unsatisfiable} program $P$\ref{lst:example3}
%   %%
%   \lstinputlisting[caption={Program $P$\ref{lst:example3}}, label={lst:example3}]{encodings/example3.lp}
%   %%
%   Now consider that we want to find reasons why this program is unsatisfiable.
%   %
%   We might find different explanations depending how do we frame it as the problem of finding a valid foil.
%   %
%   First we will consider $P$\ref{lst:example3}$ = \pr$
%   and
%   $Q = \emptyset$ since we are only interested in recovering satisfiability.
%   Also, we will always consider $\addable = \emptyset$ for this example.
%   %

%   %
%   If we say that $\removable = \{ 4 \}$, then there is only one \emph{valid foil subgraph} depicted in Figure~\ref{fig:example3-1}.
%   %
%   If we however consider $\removable = \{ 2, 3 \}$, then there are three possible \emph{valid foils} depicted in Figure~\ref{fig:example3-2}.
% \end{example}
%
% \begin{figure}
%   \centering
%   \includegraphics[width=0.3\textwidth]{resources/example3-1.png}
%   \caption{Valid foil for $P$\ref{lst:example3} with respect to $Q = \emptyset$, when $\removable = \{ 4 \}$. Only (constraint) rule 4 was removed.}
%   \label{fig:example3-1}
% \end{figure}
%
% \begin{figure}
%   \centering
%   \begin{minipage}[b]{0.32\textwidth}
%     \centering
%     \includegraphics[width=\textwidth]{resources/example3-2-1.png}
%     % \label{fig:example3-2-1}
%   \end{minipage}
%   \hfill
%   \begin{minipage}[b]{0.32\textwidth}
%     \centering
%     \includegraphics[width=\textwidth]{resources/example3-2-2.png}
%     % \label{fig:example3-2-2}
%   \end{minipage}
%   \hfill
%   \begin{minipage}[b]{0.32\textwidth}
%     \centering
%     \includegraphics[width=\textwidth]{resources/example3-2-3.png}
%     % \label{fig:example3-2-3}
%   \end{minipage}
%   \caption{Valid foils for $P$\ref{lst:example3} with respect to $Q = \emptyset$,
%   when $\removable = \{ 2, 3 \}$.
%   Foils left and middle correspond to remove only rules $2$ and $3$ respectively, whereas left foil correspond to remove both.}
%   \label{fig:example3-2}
% \end{figure}

\subsubsection{Selecting the best Foil}
\label{sec:best-foil}

\paragraph{Motivation and Context}
\begin{itemize}
  \item Among all possible explanations, humans tend to select the most suitable ones according to different criteria.
  %
  \item Since our framework allows full flexibility in generating possible foils, we also need a good way to identify the most appropriate ones.
  %
  \item
  In the social sciences, several notions of preference or selection criteria have been discussed, ranging from the degree of difference between the fact and foil worlds (the smaller, the better), to temporal or probabilistic considerations.
  This is well studied in~\cite{miller19}.
  %
  \item Other contrastive approaches, such as \cite{eigeoe23a}, only allow to minimize the difference between both worlds or restrict attention to minimal ones.
  %
  \item We pursue a more general perspective by introducing an abstract \emph{cost function} that assigns each foil a numerical value, thus establishing an order relation among foils.
  %
  \item Each concrete implementation of this function represents a criterion that can be used to select among foils by minimization.
  %
  \item Examples of possible criteria include:
  \begin{itemize}
    \item the number of rules that were added or removed and the type of such rules (e.g., constraints vs. standard rules),
    % \item the differences between what holds true or false in the two models,  % this is for contrastive
    \item the difference between the two models in terms of atoms that are true in one but not the other,
    \item domain-specific distances, such as the cost of modifying a plan in planning scenarios.
  \end{itemize}
  %
  \item The identification, definition, and implementation of such criteria deserve dedicated effort, as they directly affect the relevance and usefulness of the explanations from a user’s perspective.
  %
  \item In the following, we define the abstraction formally and propose several implementations that, in our view, cover common use cases—while remaining flexible for systems to define their own.
\end{itemize}


\begin{definition}[Foil cost function]\label{def:foil-cost}
  Given
  \begin{itemize}
    \item a query $Q$,
    %
    \item a reference program $\pr$,
    %
    \item a set of removable labelled rules $\removable \subseteq \pr$,
    %
    \item and a set of addable labelled rules $\addable$,
  \end{itemize}
  %
  a \emph{foil cost function} for $(\pr, \addable, \removable, Q)$ is a function
  %
  \[
    \foilcost_{\pr,\addable,\removable,Q} :
    \foils(\pr, \addable, \removable, Q) \rightarrow \mathbb{N}.
  \]
  that assigns each foil $(\pf, \m_f)$ a numerical value representing a cost with respect to the reference program.
\end{definition}

\begin{definition}[Best foils]\label{def:best-foils}
  Given
  \begin{itemize}
    \item a query $Q$,
    %
    \item a reference program $\pr$,
    %
    \item a set of removable labelled rules $\removable \subseteq \pr$,
    %
    \item and a set of addable labelled rules $\addable$,
    %
    \item and a foil cost function $\foilcost$,
  \end{itemize}
  %
  the set of \emph{best foils} is defined as
  %
  \[
  \bestfoils(\pr, \addable, \removable, Q, \foilcost)
    = \operatorname*{arg\,min}_{(\pf, \m_f) \in \foils(\pr, \addable, \removable, Q)}
      \foilcost_{\pr,\addable,\removable,Q}(\pf, \m_f).
  \]
\end{definition}

\paragraph{Discussion}
\begin{itemize}
  %
  \item The idea to find good explanations for users is that we first design and implement a good preference for selecting explanations, that is, a good cost function.
  %
  \item Then, $\bestfoils$ contains all valid foils that achieve the minimal value of the selected cost function.
  %
  \item These represent the preferred foils according to the specified preference.
\end{itemize}


\begin{example}[Program-difference cost function]\label{ex:program-difference-cost-function}
  For a given abduction setup $(\pr, \addable, \removable, Q)$.
  \comment{S: This abduction setup is something we use a lot before already, perhaps we want to define it before}
  %
  We define the particular foil cost function \emph{program difference} $\varphi$,
  % \[
  %   \pdiff_{\pr,\addable,\removable,Q} :
  %   \foils(\pr,\addable,\removable,Q) \rightarrow^{} \mathbb{N}
  % \]
  defined as follows:
  \[
    \pdiff(\pf, \m_f)
    = |\,\pr \,\triangle\, \pf\,|,
  \]
  where $\triangle$ denotes the \emph{symmetric difference} between the sets of rules
  in $\pr$ and $\pf$.
  %
\end{example}

\paragraph{Discussion on Program Difference Function}
\begin{itemize}
  \item This cost function reflects how many rules differ between the reference and the foil program i.e. how many rules were added/removed.
  %
  \item Minimizing $\pdiff$ therefore selects foils that are syntactically closest to the reference program.
  %
  \item We belive this is one of the typical preferences that we can use.
  %
  % \item Also, note that $\pdiff$ previous definition is equivalent to
  % \[
  % \pdiff(\pf, \m_f)
  %   = |\removable'| + |\addable'| = |\pr \setminus \pf| + |\pf \setminus \pr|
  % \]
\end{itemize}

\begin{example}[Selecting minimal foils using the program-difference cost]\label{ex:best-foils}
  By applying
  $\pdiff$ to the foils obtained in  Example~\ref{ex:example2}
  we assign each foil a value proportional to the number of rules that differ from the reference program.
  %
  In this case, the first two foils that remove a single rule receive a cost of $1$, while the foils removing both rules receives a cost of $2$.
  %
  Therefore,
  \[
  \bestfoils(P2, \emptyset, \{r6, r7\}, \{ \neg p \}, \pdiff)
    = \{(\pf, \m_f) \in \foils(P2, \emptyset, \{r6, r7\}, \{ \neg p \})
        \mid |\,P2 \triangle \pf\,| = 1\}.
  \]
  %
  Minimizing $\pdiff$ thus selects the two top foils from Figure~\ref{fig:foils},
  which represent the \emph{cardinality}-minimal deviations \comment{S2B: What do you mean here?} from the reference program needed to recover satisfiability.
  %
  This example illustrates the use of the preferences to select the foils which made the least changes to the original program.
\end{example}


%%%%%%%%%%%%%%%%%% CONTRASTIVE EXPLANATIONS

\subsection{Contrastive Explanations}
\label{sec:contrastive-explanations}

\paragraph{Context and Motivation}
\begin{itemize}
  %
  \item On top of using abduction to figure out valid foils, humans tend to leverage from the differences between the \emph{reference} and the \emph{foil} when explaining something.
  %
  \item A contrastive explanation compares this \emph{reference world} with an \emph{foil world} where the outcome differs.
  %
  \item With this comparison we  will be able to use causal relations \emph{hidden} in constraints by using \emph{existential satisfaction}, defined below.
  %
\end{itemize}

\begin{definition}[Existential Satisfaction]
  Given two sets of atoms $\m_1$ and $\m_2$ we define the \emph{existential satisfaction} relation, written
  \[ \m_1,\m_2 \models · \]
  that holds according to the following cases:
  \begin{itemize}
    \item for a literal $l$ of the form $a$ or $\neg a$
    \begin{itemize}
      \item $\m_1,\m_2 \models a \iff a \in \m_1 \vee a \in \m_2$
      \item $\m_1,\m_2 \models \neg a \iff a \notin \m_1 \vee a \notin \m_2$
    \end{itemize}
    \item for sets of literals $B$
    \begin{itemize}
      \item $\m_1,\m_2 \models $B$ \iff \m_1,\m_2 \models l$ for every $l \in B$.
    \end{itemize}
    \item for a rule $r$ of the forms \eqref{f:disjunctive-rule} or \eqref{f:choice-rule}
    \begin{itemize}
      \item $\m_1,\m_2 \models r \iff \m_1,\m_2 \models \Bd{r}$
    \end{itemize}
  \end{itemize}
\end{definition}

\paragraph{Discussion on Existential Satisfaction}
\begin{itemize}
  \item Will be used to identify the conflict constraints among the masks used for a contrast.
  \item Is a relaxed notion of satisfaction that can be read as \emph{this constraint would have been fired}.
\end{itemize}

\begin{definition}[Contrastive Subgraph]
  Given
  \begin{itemize}
    \item a set of literals $Q$ refered as \emph{query},
    %
    \item a reference program-model pair $\langle \pr, \m_r \rangle$ such that $\m_r \models \pr$, $\m_r \not\models Q$, and its correspondant subgraph $\mgpi{\pr}{\m_r} = \langle V_r, E_r \rangle$,
    %
    \item sets $\addable$ and $\removable$, of \emph{addable} (respectively \emph{removable}) rules, a \emph{valid foil program-model pair} $(\pf, \m_f) \in \foils(\pr, \addable, \removable, Q)$, and its correspondant model subgraph $\mgpi{\pf}{\m_f} = \langle V_f, E_f \rangle$.
    %
    \item a program graph $\pg{\pr \cup \pf} = \langle \Vc\cup \Vd\cup \Va, \Epos\cup \Eneg \rangle$,
    \comment{
    {\bf Brais:} the labels of the rules in the programs might not coincide, so that if we do the union we might end up having repeated rules, different boxes. That's fine, in fact, we might want that. In labelled programs you sometimes want to have the same rule with different labels because they represent differnt knowledge sources.
    \\
    {\bf Son:} This is interesting but how do you know that a specific source of knowledge is appropiate for a query and not another one?
    It might be better to require that same rule must have the same label?
    \\
    {\bf Brais:} we might define a distance function that prefers the contrastive graph that includes a particular label (labels become the box node IDs).
    But then the distance function has to have access to that...
    }
  \end{itemize}
  then
  %
  a \emph{contrastive subgraph} is the tuple
  \[
  \cg{\pr}{\pf}{\m_r}{\m_f} =
  \langle
    \Vcon, % 1. reference nodes, foil nodes, constraint nodes (or conflict nodes?)
    \langle \Eposcon, \Enegcon \rangle  % fact/foil positive edges, negative edges
  \rangle
  \]
  %
  where
  \begin{itemize}
    \item  $\Vcon = V_r \cup V_f \cup  \{ \Lb{r} \mid (r \in \pr \cup \pf) \land (\iscons{r}) \land (\m_r, \m_f \models \Bd{r}) \}$
    \comment{
      {\bf Son:} what about other rules whose body is existentially satisfied by $\m_r$ and $\m_f$, but not by $\m_r$ nor $\m_f$ alone?
    }

    \item $\Eposcon = \{(v1, v2) \mid (v1, v2) \in \Epos \land v1,v2 \in \Vcon\}$
    \item $\Enegcon = \{(v1, v2) \mid (v1, v2) \in \Eneg \land v1,v2 \in \Vcon\}$
    \item $\Enegcon = \{ (a, \ell) \mid (a, \ell) \in \Eneg \land [ (\m_r \models a) \oplus (\m_f \models a)]\}$
  \end{itemize}
\end{definition}
%
\begin{proposition}
  Given a \emph{contrastive graph} $\cg{\pr}{\pf}{\m_r}{\m_f}$,
  \begin{itemize}
    \item $\mgpi{\pr}{\m_r}$ is a subgraph of $\cg{\pr}{\pf}{\m_r}{\m_f}$
    \item $\mgpi{\pf}{\m_f}$ is a subgraph of $\cg{\pr}{\pf}{\m_r}{\m_f}$
    \item $\cg{\pr}{\pf}{\m_r}{\m_f}$ is a subgraph of $\pg{\pr \cup \pf}$.
  \end{itemize}
\end{proposition}
%

%% contrastive
% pg1 --> model mask1 (all alternative justifications) --> causal mask1
% pg2 --> model mask2                                  --> causal mask2

% causal mask1 --> pg2 ?? % could be a distance function that ensures we keep as close as possible to the alternative chosen in causal mask1

% UnionGraph + causal mask1 + causal mask2 -->  Contrastive Graph  (asplain)
% UnionGraph + model mask1  + model mask2 -->  Contrastive Graph  (paper)

\paragraph{Discussion Points}
\begin{itemize}
  %
  \item We can build contrastive explanations or contrastive graphs only when we have a {\color{blue} satisfiable reference program}.
  %
  \item On top of the model subgraphs, the contrastive subgraphs additionally highlight: (1) \emph{constraint conflicts} and (2) \emph{negative edges}.
  %
  \item {\color{blue} Important: asplain allows the reference to fulfill the query. In those case, the reference and the foil are the same and we use that to capture positive justifications of queries as well as contrastive explanations. See below a discussion on that.}
  %
\end{itemize}

\paragraph{Discussion on Types of Contrasts}
\begin{itemize}
  \item We may separate contrasts in types depending on the (dis)equalities among the model subgraphs used $\mgpi{\pr}{\m_r} = \langle V_r, E_r \rangle$ and $\mgpi{\pf}{\m_f} = \langle V_f, E_f \rangle$.
  \item We propose the following types
  \begin{itemize}
    \item when $\pr = \pf \land \m_r = \m_f$, so that $\m_r \models Q$ then we call it \emph{positive justification}.
    \item when $\pr = \pf \land \m_r \neq \m_f$ then we call it \emph{alternative contrastive explanation}.
    \item when $\pr \neq \pf$ then we call it \emph{hypothetical contrastive explanation}.
  \end{itemize}
  \item Note that, when we start from an unsat program (as in Section~\ref{sec:abductive-explanations}) we can only compute hypothetical contrastive explanations as we need a foil program $\pf$ for having any $\m_f \models Q$.
\end{itemize}

\paragraph{Finding Contrastive Explanation for Queries}
\begin{itemize}
  \item We first start from the assumption that there exists some referece model $\m_r$ of some reference program $\pr$ that has been shown to (or selected by) the user.
  %
  \item Then the user wonders why some query $Q$ is not true in the reference.
  %
  \item We use abduction to find a $\mgpi{\pf}{\m_f} \in Foil(\pr, \addable, \removable, Q)$, for some $\removable$ and $\addable$.
  %
  \item Sets $\removable$ and $\addable$ can vary depending on the particular application.
  %
  \item Finally, we compute $\cg{\pr}{\pf}{\m_r}{\m_f}$
\end{itemize}


\begin{figure}
  \centering
  \begin{tabular}{cc}
    \includegraphics[scale=0.05]{resources/c1.png} &
    \includegraphics[scale=0.05]{resources/c2.png} \\
  \end{tabular}
  \caption{Visualizations of the two contrastive graphs for the best foils of $P2$ in Example~\ref{ex:example2}.}
  \label{fig:contrastive}
\end{figure}

\begin{example}[Contrastive Explanations for a query]\label{ex:example4}
  Following our examples, let be $(P2_f, \m 2_f)$ be a foil in
  $\bestfoils(P2, \emptyset, \{r6, r7\}, \{ \neg p \}, \pdiff)$
  %
  we can build a contrastive graph $\cg{P2}{P2_f}{\m 2}{\m 2_f}$.
  The visualization of these graphs is shown in Figure~\ref{fig:contrastive}.
  %
  The first contrastive graph (left) corresponds to the foil that removes rule $7$,
  and can be read as if James had not been forced to be on holiday,
  he would have been working, otherwise it would have violated the constraint of being either on holiday or working.
  If he had been working, he would have taken the antidote and therefore not been poisoned.
  %
  The second contrastive graph (right) corresponds to the foil that removes rule $6$,
  and can be read as if James had not drunk the poison,
  he would not have been poisoned.
  % %
  % The first is an \emph{alternative contrastive explanation} as the program has not been changed (that is, $\pr = \pf$), the other two are \emph{hypothetical contrastive explanations}
  % %
\end{example}


\paragraph{Visualization of Contrastive Explanations}
\begin{itemize}
  \item This visualization show the comparison of all involved graphs.
  \item As before, the reference model subgraph $\mgpi{\pr}{\m_r}$ is coloured in purple whereas the foil model subgraph $\mgpi{\pf}{\m_f}$ is coloured in green.
  \item Nodes and eges that are not in $\mgpi{\pf}{\m_f}$, are shown with less opacity.
  \item Rule nodes that can be removed (i.e., that are in $\removable$) are shown with a dashed border.
  \item Removed rules are shown with a red border, whereas added rules are shown with a blue border.
  \item Finally, for those constraint rule nudes, that are existentially statisfied by $\m_r$ and $\m_f$ together, have a red background.
  % \comment{This case it's maybe not the best example as our interity constraints here only give us that w and h cannot be together}
\end{itemize}
%

%
\paragraph{Small Discussion on types of queries}
\begin{itemize}
  %
  \item The type of query is implicitly given by the satisfaction relation between $Q$ and $\m_r$.
  \begin{itemize}
    %
    \item If $\m_r \models Q$, then $Q$ is a \emph{Why query}. It does not require contrastive for being answered but our framework support this as a contrast as well (as mentioned earlier).
    %
    \item If $\m_r \nvDash Q$, then $Q$ is a \emph{Why not query}, asking for contrastive explanation of $Q$ starting from $\pr$ and $\m_r$ (and some sets $\addable$ and $\removable$).
  \end{itemize}
  %
  We do not answer in different ways depending on a taxonomy over a query. Queries are always sets of literals, and are answered always in the same way.
\end{itemize}
%


\subsubsection{Selecting the Best Contrastive explanations}
\label{sec:best-contrastive}

\paragraph{Motivation}
\begin{itemize}
  \item In practice, we can still use the $\foilcost$ plus $\mathit{BestFoils}$ approach to select among the best foil to make a contrast with.
  %
  \item However, since those notions are designed without a starting \emph{reference} model in mind, we cannot make interesting differences (semantic based) among the reference and foil models alone.
  %
  \item For instance, in Example~\ref{ex:example4}, we cannot notice any difference between contrastive explanations (2) and (3) by using the $\pdiff$ foil cost function alone, since they are equivalent in terms of removed rules.
  %
  \item However, explanation (2) requires less changes, as in explanation (3) we moreover had to pick $w$ instead of $h$.
  %
  \item In the following, we define an extension of the previous definitions~\ref{def:foil-cost} and~\ref{def:best-foils}, for defining preference that include a \emph{reference} model $\m_R$.
\end{itemize}


\begin{definition}[Contrast cost function]\label{def:contrast-cost}
  Given
  \begin{itemize}
    \item a query $Q$,
    %
    \item a reference program-model pair $(\pr, \m_r)$,
    %
    \item a set of removable labelled rules $\removable \subseteq \pr$,
    %
    \item and a set of addable labelled rules $\addable$,
  \end{itemize}
  %
  a \emph{contrast cost function} for $((\pr, \m_r), \addable, \removable, Q)$ is a function
  %
  \[
    \contrastcost_{(\pr, \m_r),\addable,\removable,Q} :
    \foils(\pr, \addable, \removable, Q) \rightarrow \mathbb{N}.
  \]
  that maps each foil $(\pf, \m_f)$ to a numerical value representing its cost with respect to the reference program-model pair $(\pr, \m_r)$.
\end{definition}

\begin{definition}[Best constrast]\label{def:best-contrasts}
  Given
  \begin{itemize}
    \item a query $Q$,
    %
    \item a reference program $(\pr, \m_r)$,
    %
    \item a set of removable labelled rules $\removable \subseteq \pr$,
    %
    \item and a set of addable labelled rules $\addable$,
    %
    \item and a contrast cost function $\contrastcost_{(\pr, \m_r),\addable,\removable,Q}$,
  \end{itemize}
  %
  the set of \emph{best contrasts} is defined as
  %
  \[
  \bestcontrasts((\pr, \m_r), \addable, \removable, Q, \contrastcost)
    = \operatorname*{arg\,min}_{(\pf, \m_f) \in \foils(\pr, \addable, \removable, Q)}
      \contrastcost_{(\pr, \m_r),\addable,\removable,Q}(\pf, \m_f).
  \]
\end{definition}

\begin{example}[Model-difference cost function]\label{ex:model-difference-cost-function}
  For a given abduction setup $(\pr, \addable, \removable, Q)$ with reference model $\m_r$,
  we define the \emph{model-difference} contrast cost function as
  \[
   \mdiff_{(\pr, \m_r),\addable,\removable,Q}(\pf, \m_f)
      = |\,\m_r \,\triangle\, \m_f\,|,
  \]
  where $\triangle$ denotes the symmetric difference between the models $\m_r$ and $\m_f$.

\end{example}

\begin{example}[Reference–Foil difference cost function]\label{ex:reference-foil-difference-cost-function}
  Extending the previous idea, we define the \emph{reference-foil difference}, contrast cost function as
  \[
    \rdiff_{(\pr, \m_r),\addable,\removable,Q}(\pf, \m_f)
      =\mdiff_{(\pr, \m_r),\addable,\removable,Q}(\pf, \m_f)
      + \pdiff_{\pr,\addable,\removable,Q}(\pf, \m_f).
  \]
\end{example}

\comment{Brais2All: do you feel this example is too much? we can also add another function where we penalize removing/adding more than semantic differences
  S: I liked the example and tried to make it simpler, but could be made even simpler,
  perhaps we leave the \mdiff\ and  just make a comment about creating another combined function and introduce the need for priorities.}

\paragraph{Discussion}
\begin{itemize}
  \item The setup for finding the best contrastive explanations is the same as for selecting the best foil.
  \item $\mdiff$ is a \emph{semantic difference} measuring how many atoms differ between the reference and foil models.
  \item $\rdiff$ integrates both syntactic and semantic differences, penalizing foils that diverge from the reference either in their rules or in their resulting models.
  \item Note, now that we can have alternative and hypothetical explanations.
  \item We can consider different priorities among those cost functions.
  In our case, \rdiff\ gives equal importance to both syntactic and semantic differences, but we could also define a weighted sum to prioritize one over the other.
  \comment{S: Can we argue that this can be mapped into a single function @Son perhaps you can help with this?}
\end{itemize}

\begin{example}[Selecting the best contrastive explanations]\label{ex:best-contrastive-explanations}
  Following our example, the two contrastive explanations depicted in Figure~\ref{fig:contrastive},
  have the same cost according to the $\pdiff$ function, that is, a weight of $1$ each.
  However, if compared using $\mdiff$, which counts the differences among $\m_r$ and $\m_f$,
  is easy to see that contrast we obtain
  a weight of $6$ for the foil corresponding first explanation removing rule $r7$,
  $4$ for the foil corresponding to second explanation removing rule $r6$.
  %
  Note how when using $\mdiff$ alone, we do not penalize any addition/removal to the reference program.
  %

  %
  Alternatively, we can use $\rdiff$ instead that can be computed as the sum of the weights previously reported for the other two cost functions.
  The ordering among foil induced by this, better matches the intuition of \emph{closeness} between the reference and foil.
  %
  In short, the second explanation would be the preferred explanation since the hypothetical contrastive world is closer to the reference.
  \comment{
    Brais -- my intuition was that for this cost function (1) and (2) would collide
    however, strange effect: when we use this cost function, removing fact $d.$ effectively leads to increasing of $2$ units in the cost, since we remove the rule and the atom as well...
    Nevertheless, this effect can be interesting in other cases, where the atom could be derived by other rule?
  }
  %

  %

\end{example}

% \subsection{Relation to Support Graphs~\cite{cabmun24a}}
% %
% We refer back to~\cite{cabmun24a}, where the notion of \emph{support graph} or \emph{explanation} of an answer set with respect to a program is defined.
% %
% There, the nodes of the graph are only the atoms in the answer set, rules are not included as they are a technical detail of the program that might be hard to understand for the end-user.
% %
% The edges between the atoms, however, are obtained from the body of the rules in the program, connecting body literals with the the atoms in the head head and following some conditions.
% %
% Those conditions are used as the semantics for \emph{Justified Models}, whose relation with other approaches have been partly discussed in \cite{cabmun24a}.
% %
% Perhaps the most important condition is that the graphs have to \emph{select} one and only one rule to justify each atom in the answer set by defining an injective $\lambda$ function that maps each atom to the rule that justifies it.
% %
% Both an answer set of the program and the $\lambda$ function can be seen as a mask that can be applied on top of the program graph, obtaining a corresponding \emph{support graph}.
% %
% In~\cite{cabmun23a} two operations to select the relevant information within an explanation are introduced:
% first an operation to remove nodes, but preserving the transitive connection of the remaining nodes;
% and a second operation to prune edges, to remove non causal relations from the program.
% %
% We will use this two operations to obtain the all the corresponding support graph with respect to each answer set and a valid $\lambda$ function, from the program graph which is unique for each program.
% %
% However, in the case of the edge-prunning operation, it can be too weak for our purposes.
% %

% %
% \begin{definition}[Mask]
%   Given a program graph $\pg{P} = \langle \Vc \cup \Vd \cup \Va, \Epos, \Eneg \rangle$,
%   and an answer set $\m \subseteq \Va$ of $P$,
%   an \emph{mask} of $\pg{P}$ under $\addable$ is a function $\lambda: \m \rightarrow \Vc \cup \Vd$ such that:
%   \begin{itemize}
%     \item $\lambda$ is injective {\color{blue} in $\lambda^{-1}(\Vd)$}
%     \item $\forall a \in \m, \lambda(a) = r \rightarrow \m \models r$ \comment{TODO: allow non-injective mask for choice rules}
%     \comment{Note: We check cycles after inducing the subgraph.}
%   \end{itemize}
% \end{definition}
% %
% Notes:
% %
% \begin{itemize}
%   \item Intuitively, is a function that selects one supported rule for each atom in the answer set.
%   \item It can be applied to the program graph which gives us a subgrap that justifies each atom in the answer set.
% \end{itemize}
% %
% % \begin{definition}[Edges Mask]
% %   Given a program graph $\pg{P} = \langle \Vc \cup \Vd \cup \Va, \Epos, \Eneg \rangle$,
% %   and an answer set $\m \subseteq \Va$ of $P$,
% %   an \emph{mask} of $\pg{P}$ under $\addable$ is a function $\lambda: \m \rightarrow \Epos$ such that:
% %   \begin{itemize}
% %     % Lambda maps each atom to one of its incoming edges
% %     \item $\forall a \in \m, \lambda(a) = (l, a) \land l \in \Epos$
% %     % Disjunctive rules can only justify one atom
% %     \item $\forall a1, a2 \in \m$ such that $\lambda(a1) = (l1, a1)$ and $\lambda(a2) = (l2, a2)$, then $l1 = l2 \rightarrow a1 = a2$.
% %     % The selected rule must be satisfied by the answer set
% %     \item $\forall a \in \m, \lambda(a) = (l, a) \rightarrow \m \models \InvLb{l}r$
% %     \comment{Note: We check cycles after inducing the subgraph.}
% %   \end{itemize}
% % \end{definition}
% %
% \begin{definition}[Edge Mask]
%   Given a program graph $\pg{P} = \langle \Vc \cup \Vd \cup \Va, \Epos, \Eneg \rangle$,
%   and an answer set $\m \subseteq \Va$ of $P$,
%   a \emph{mask} of $\pg{P}$ explaining $\m$ is a set $EM \subseteq \Epos$ such that:
%   \begin{itemize}
%     % There is an edge justifying each atom in the answer set such that the rule it comes from is satisfied by the answer set
%     \item $\forall a \in \m, \exists (l, a) \in EM$ such that $\m \models \InvLb{l}$.
%     % If a rule is used to satisfy an atom, then all its incoming edges are in the mask
%     \item $forall (l, a) \in EM$, such that $\m \models \InvLb{l}$, then $\forall (a', l) in \Epos$ it must hold that $(a', l) \in EM$.
%     % Only one incoing edge per atom
%     \item $\forall  (l1, a1),(l2, a2) \in EM$, it must hold $(a1 = a2) \rightarrow (l1 = l2)$
%     % Disjunctive rules can only justify one atom
%     \item $\forall (l1, a1),(l2, a2) \in EM$, it must hold $(l1 = l2) \land (l1 \in \Vd) \rightarrow (a1 = a2)$.
%   \end{itemize}
% \end{definition}
% %
% Notes:
% %
% \begin{itemize}
%   \item \addable mask then would be a subset of edges of the program graph that selects one edge for each atom in the answer set.
%   \item This alternative definition of mask may better fit the current implementation.
%   \item It's equivalent to the previous.
% \end{itemize}
% %

% %
% \begin{definition}[Answer Set Explanation Graph]
%   Given a program graph
%   $\pg{P} = \langle \Vc \cup \Vd \cup \Va, \Epos, \Eneg \rangle$,
%   corresponding to a ASP program $P$,
%   and an answer set $\m \subseteq \Va$ of $P$,
%   and a \emph{mask} $\lambda: \m \rightarrow \Vc \cup \Vd$ of $\pg{P}$ under $\m$,
%   an explanation of $\m$ under $P$ is a directed graph
%   \[    G_{\lambda} = \langle V, E \rangle    \]
%   where:
%   \begin{itemize}
%     \item $V = \m \cup Im(\lambda)$
%     \item $E = \{ (\ell, a) \in \Epos \mid \lambda(a) = \ell \} \cup \{ (a, \ell) \in \Epos \mid \ell \in Im(f) \}$
%     \item {\color{red} There is no cycles in $G_{\lambda}$.}
%   \end{itemize}
% \end{definition}
% %
% Notes:
% \begin{itemize}
%   \item Intuitively, this graph is a subgraph of the support graph, where we only keep the nodes in the answer set and the rules that justify them following a particular $\lambda$.
%   \item It only contains positive edges.
%   \item Find an example of a mask and the corresponding answer set explanation in Figure~\ref{fig:mask}.
%   \item For any answer set $\m$ of a program $P$ there is always at least one mask $\lambda$ such that the technical explanation $G_{\lambda}$ is a directed acyclic graph (DAG) (pontentially many). \comment{\m have to prove this by proving the correspondance with Justified Models.}
%   \item In Figure~\ref{fig:mask}, note that there is another mask $\lambda_2$ for explaining $\m_1$ that justifies the atom $a$ with rule $5$, that is $\lambda_2(a) = 5$.
% \end{itemize}
% %
% \begin{definition}[Answer Set Explanation Graph with Edges Mask]
%   Given a program graph
%   $\pg{P} = \langle \Vc \cup \Vd \cup \Va, \Epos, \Eneg \rangle$,
%   corresponding to a ASP program $P$,
%   and an answer set $\m \subseteq \Va$ of $P$,
%   and a \emph{edge mask} $EM \subseteq \Epos$ explaining $\m$,
%   an explanation of $\m$ under $P$ is a directed graph
%    \[    G_{EM} = \langle V, EM \rangle    \]
%   where
%   % v is any origin or destination of an edge in $EM$
%   $V = \{ v \mid \exists (v, w) \in EM \vee \exists (w, v) \in EM \}$
% \end{definition}
% %

% %
% \begin{figure}
%   \centering
%   \includegraphics[width=0.9\textwidth]{resources/mask.png}
%   \caption{Mask.
%   The entire program graph $G_{P_{1}} = \{\Vc, \Vd, \Va, \Epos, \Eneg\}$ can be seen, but the highlighted part of the graph explains the answer set $\m_1 = \{s,w,a,d\}$.
%   This subgraph is the techincal explanation $G_{\lambda} = \langle V, E \rangle$ induced from a mask $\lambda: \m_1: \rightarrow $ where $\lambda(s) = 1$, $\lambda(w) = 4$, $\lambda(a) = 2$ and $\lambda(a) = 3$.}
%   \label{fig:mask}
% \end{figure}
% %

% {\color{gray}
% %
% \begin{definition}[Technical Non-Causal Explanation]
%   Given a program graph
%   $\pg{P} = \langle \Vc \cup \Vd \cup \Va, \Epos, \Eneg \rangle$,
%   corresponding to a ASP program $P$,
%   and an answer set $\m \subseteq \Va$ of $P$,
%   and an injective function $\lambda: \m \rightarrow \Vc \cup \Vd$ such that selecting a rule $r$ such that $\m \models r$ to justify each atom,
%   a techincal explanation of $\m$ under $P$ is a directed graph
%   \[    G_t = \langle V_{+}, V_{-}, E_{t}^{+}, E_{t}^{-} \rangle    \]
%   where:
%   \begin{itemize}
%     \item $V_{+} = \m \cup Im(\lambda)$
%     \item $V_{-} = \bigcup_{l \in Im(\lambda)}{\Bdn{\InvLb{l}}}$
%     \item $E_{t}^{+} = \{ (\ell, a) \in \Epos \mid \lambda(a) = \ell \} \cup \{ (a, \ell) \in \Epos \mid \ell \in Im(\lambda) \}$
%     \item $E_{t}^{-} = \{ (a, \ell) \in \Eneg \mid \ell \in Im(\lambda) \land a \in \Bdn{\InvLb{l}} \}$
%     \item {\color{red} There is no cycles in $G_t$.}
%   \end{itemize}
%   %
%   \comment{TODO: this version is intended to be used for correspondance with xASP, left for future work}
% \end{definition}
% %
% \begin{figure}
%   \centering
%   \includegraphics[width=0.9\textwidth]{resources/tech-non-causal.jpg}
%   \caption{Technical Non Causal Explanation}
%   \label{fig:gt_noncausal}
% \end{figure}
% }
% %


% % % TODO: the correspondance
% % Moreover, a proper support graph is obtained by applying the node forgetting operation to the technical explanation, effectively removing any rule referencing node and keeping only nodes referencing atoms.
% % %
% % That is $G = forget(G^t, \Vc \cup \Vd)$.
% % %
% % \begin{proposition}
% %     Let $G_{P} = \{\Vc, \Vd, \Va, \Epos, \Eneg\}$ be the program graph for program $P$,
% %     and a mask \lambda $G_{\lambda} = \langle V_t, E_t \rangle$ be a causal technical explanation of an answer set $\m$ under a program $P$,
% %     then graph $G^s = forget(G_{\lambda}, \Vc \cup \Vd)$ is a valid support graph of $\m$ under $P$.
% % \end{proposition}
% % %

% % %
% % In~\cite{cabmun24a} support graphs are introduced as a way to globally explain a particular answer set of a program.
% % %
% % Then, authors explain how to obtain \emph{local explanaitions} or \emph{proofs} for particular atoms from the suppport graph.
% % %
% % This is done by recursively traversing the graph backwards from the explained atom.
% % %
% % It is trivial to see how this can also be done from the technical explanation although this time the obtained \emph{tree} or \emph{proof} will also include the rule nodes.
% % %





% \subsection{Whynot queries}

% %
% Three different concepts:
% \begin{itemize}
%     \item \textbf{Natural language question}:
%     %
%     human users express they information needs in natural language.
%     %
%     It's inherently ambiguous and the same expression can be interpreted in many ways, that is, the relation between an expression and a formalized query it's $N:N$.
%     %
%     \item \textbf{Query}:
%     %
%     a formal/mathematical object that encodes an infromation need.
%     %
%     Dependant of the system.
%     %
%     \item \textbf{Answer}:
%     %
%     deterministic and replicable with respect to the query and system.
%     %
%     It fulfils the information need of the original natural language question.
%     %
% \end{itemize}

% %
% From social sciences~\cite{miller19} we know that human explanations are:
% %
% \begin{enumerate}
%     \item \textbf{Selected}:
%     %
%     a good explanation only include the relevant information and exclude irrelevant details.
%     %
%     This filter is highly relative to the persons involved and their contexts which connects with point 2.
%     %
%     \item \textbf{Social}:
%     %
%     in an explanation, we have at least two involved entities: the \emph{explainer} and the \emph{explainee}.
%     %
%     In our case, asplain and the user respectively.
%     %
%     The explanation is always \emph{social interaction}, even if one of the entities is a non-human system.
%     %
%     As a social interaction, it's highly dependant of the context, and the entities's contexts.
%     %
%     Naturally, the contents (what info is included/excluded) and the form (language, tone, extension, etc.) of the explanation are set by the \emph{explainer}.
%     %
%     But in the case of humans, the explainer is able to \textbf{adapt} both to the \emph{explainee} context.
%     %
%     For instance, when explaining the reasons behind the disease of a patient, the doctor (\emph{explainer}) will not provide the same explanation to her colleges than to the patient.
%     %
%     This adjustments include the language (which words are chosen), the tone, the length but also which info is included/excluded and the importance given to each piece of information (this could even affect the order the information is presented, but we are not controlling that in asplain).
%     %
%     \item \textbf{Contrastive}:
%     %
%     this point mainly speaks about which type of queries humans often ask, and how do they ask them.
%     %
%     We can synthetise this in two points.
%     \begin{itemize}
%         \item \textbf{Most queries are a ''why not´´}:
%         %
%         humans often ask for an explanation when they are surprised by an unexpected event and ask for explanation of why their expectations weren't fulfilled.
%         %
%         That is, the \emph{explainee} pressuposes a world / expects an outcome / has a mental model (from now on the \emph{default world}) that is broken by the real events (that Miller refers to as \emph{fact}, and we as the \emph{reference world}).
%         %
%         For instance, let's say that Q goes to visit James Bond expecting him to be fine, only to find out that he died poisoned.
%         %
%         There, Q asks \emph{Why did James died poisoned?} or \emph{\textbf{Why} is \textbf{not} James alive?}.
%         %
%         According to Miller, both questions actually map to the same query \textbf{Why not alive} since, disregarding how Q formulated his information need in natural language, what is important what was assumed by Q's default world (James should have been alive).
%         %
%         Human
%         %

%         %
%         This does not apply to the 100\% of the questions made by humans,
%         %

%     \end{itemize}
%     %

%     %
%     \item \textbf{Causal}:
% \end{enumerate}
% %

% \subsection{Contrastive explanations}

% \begin{itemize}
%     \item \addable contrastive explanation compares a reference model to a contrasted model.
%     \item It can cover also cases for justifying something that is true in the model.
%     So it might subsume other types of explanations that are only causal.
%     \item Can be formalized as a graph.
%     But has to add a lot of information into the edges and nodes.
%     \item \textbf{Query:} Identifies what atoms should/shouldn't be part of the model.
%     \item \textbf{Reference model:}
%     The provided model that is considered the current truth.
%     \item \textbf{Contrasted model:}
%     The model found which fulfils the query.
%     \begin{itemize}
%         \item \textbf{Same as reference model}
%         When the query is true in the current model, then the contrasted and reference model are the same.
%         The output is something like the current output of xclingo or ucorexplain\cite{alhasawe24a}.
%         \item \textbf{Alternative model}
%         When the query is not true in the current model but it is true without having to change the input (no abducible needed).
%         This is the case where another model of the same program (with the same input) satisfies the query.

%         The explanation would compare both models without need of abduction.
%         \item \textbf{Hypothetical model}
%         When the query can't be satisfied with the current input
%         Parts of the input can be abducted (changed) to achieve the query
%     \end{itemize}
% \end{itemize}


% \begin{definition}[Contrastive Explanation (preliminary)]
%     Let $P_{ref}$ and $P_{alt}$ be two labelled logic programs,
%     $\m_{ref} \in CM(P_{ref})$ and $\m_{alt} \in CM(P_{alt})$ be two classical models of $P_{ref}$ and $P_{alt}$ respectively,
%     let
%     $G_{ref} = \langle \m_{ref}, E_{ref}, \lambda_{ref} \rangle$ be a support graph explanation of $\m_{ref}$ with respect to $P_{ref}$,
%     and
%     $G_{alt} = \langle \m_{alt}, E_{alt}, \lambda_{alt} \rangle$ be a support graph explanation of $\m_{alt}$ with respect to $P_{alt}$.


%     \addable \emph{contrastive explanation graph} is a tuple:
%     \[
%     G = \langle V, \lambda_{ref}, \lambda_{alt}, E^c, E^i \rangle
%     \]
%     where:
%     \[
%     V  = \m_{ref} \cup \m_{alt} \cup \{ \lambda_{ref}(r) \mid r \in \text{CONSUP}(P_{ref}, \m_{ref}, \m_{alt}) \}
%     \],
%     \begin{align*}
%         E^c = {} &
%         E_{ref} \cup E_{alt}\\
%         & \cup
%         \left\{
%           (con, r) \in V \times V \mid
%           \begin{array}{l}
%             r \in CONSUP(P_{ref}, \m_{ref}, \m_{alt}), \\
%             con \in B^+(r) \\
%             con \in \m_{ref} \cup \m_{alt}
%           \end{array}
%         \right\}
%     \end{align*}
%     \begin{align*}
%         E^i = {} &
%         \left\{
%           (i, e) \in V \times V \mid
%           \begin{array}{l}
%             e \in \m_{ref} \setminus \m_{alt},
%             i \in \m_{alt} \setminus \m_{ref}, \\
%             \lambda_{ref}(e) = Lb(P_{ref}, r), \\
%             r \in SUP(P_{ref}, \m_{ref}, e), \\
%             i \in B^-(r)
%           \end{array}
%         \right\} \\
%         & \cup
%         \left\{
%           (i, e) \in V \times V \ \mid
%           \begin{array}{l}
%             e \in \m_{alt} \setminus \m_{ref},
%             i \in \m_{ref} \setminus \m_{alt}, \\
%             \lambda_{alt}(e) = Lb(P_{alt}, r), \\
%             r \in SUP(P_{alt}, \m_{alt}, e), \\
%             \text{not } i \in B^-(r)
%           \end{array}
%         \right\} \\
%         & \cup
%         \left\{
%           (con, r) \in V \times V \mid
%           \begin{array}{l}
%             r \in CONSUP(P_{ref}, \m_{ref}, \m_{alt}), \\
%             \text{not } con \in B^-(r) \\
%             con \notin \m_{ref} \cap \m_{alt}
%           \end{array}
%         \right\}
%     \end{align*}
%     % \[
%     % E^{c}_{con} = {} &
%     %     \left\{
%     %       (con, r) \in V \times V \mid
%     %       \begin{array}{l}
%     %         r \in CONSUP(P_{ref}, \m_{ref}, \m_{alt}), \\
%     %         con \in B^+(r) \\
%     %         con \in \m_{ref} \cup \m_{alt}
%     %       \end{array}
%     %     \right\}
%     % \]
%     % \[
%     % E^{i}_{con} = {} &
%     %     \left\{
%     %       (con, r) \in V \times V \mid
%     %       \begin{array}{l}
%     %         r \in CONSUP(P_{ref}, \m_{ref}, \m_{alt}), \\
%     %         \text{not } con \in B^-(r) \\
%     %         con \in \m_{ref} \triangle \m_{alt}
%     %       \end{array}
%     %     \right\}
%     % \]

% \end{definition}


% % \begin{definition}[Contrastive Explanation]
% %     Let $P_{ref}$ and $P_{alt}$ be two labelled logic programs,
% %     $\m_{ref} \in CM(P_{ref})$ and $\m_{alt} \in CM(P_{alt})$ be two classical models of $P_{ref}$ and $P_{alt}$ respectively,
% %     let
% %     $G_{ref} = \tuple{\m_{ref}, E_{ref}, \lambda_{ref}}$ be a support graph explanation of $\m_{ref}$ with respect to $P_{ref}$,
% %     and
% %     $G_{alt} = \tuple{\m_{alt}, E_{alt}, \lambda_{alt}}$ be a support graph explanation of $\m_{alt}$ with respect to $P_{alt}$.


% %     \addable \emph{contrastive explanation graph} is a tuple:
% %     \[
% %     G = \tuple{V, \lambda_{ref}, \lambda_{alt}, E^c, E^i, E^{con}}
% %     \]
% %     where:
% %     \[
% %     V  = \m_{ref} \cup \m_{alt}
% %     \],
% %     \begin{align*}
% %         E^c = {} &
% %         E_{ref} \cup E_{alt}\\
% %         & \cup
% %         \left\{
% %           (con, r) \in V \times V \mid
% %           \begin{array}{l}
% %             r \in CONSUP(P_{ref}, \m_{ref}, \m_{alt}), \\
% %             con \in B^+(r) \\
% %             con \in \m_{ref} \cup \m_{alt}
% %           \end{array}
% %         \right\}
% %     \end{align*}
% %     \begin{align*}
% %         E^i = {} &
% %         \left\{
% %           (i, e) \in V \times V \mid
% %           \begin{array}{l}
% %             e \in \m_{ref} \setminus \m_{alt},
% %             i \in \m_{alt} \setminus \m_{ref}, \\
% %             \lambda_{ref}(e) = Lb(P_{ref}, r), \\
% %             r \in SUP(P_{ref}, \m_{ref}, e), \\
% %             i \in B^-(r)
% %           \end{array}
% %         \right\} \\
% %         & \cup
% %         \left\{
% %           (i, e) \in V \times V \ \mid
% %           \begin{array}{l}
% %             e \in \m_{alt} \setminus \m_{ref},
% %             i \in \m_{ref} \setminus \m_{alt}, \\
% %             \lambda_{alt}(e) = Lb(P_{alt}, r), \\
% %             r \in SUP(P_{alt}, \m_{alt}, e), \\
% %             \text{not } i \in B^-(r)
% %           \end{array}
% %         \right\}
% %     \end{align*}
% %     \begin{align*}
% %         E^{con} = {} &
% %         \left\{
% %           (c2, c1) \in V \times V \mid
% %           \begin{array}{l}
% %             r \in CONSUP(P_{ref}, \m_{ref}, \m_{alt}), \\
% %             \text{not } con \in B^-(r) \\
% %             con \notin \m_{ref} \cap \m_{alt}
% %           \end{array}
% %         \right\}
% %     \end{align*}
% % \end{definition}

% \begin{itemize}
%     \item $CONSUP(P,\m_1,\m_2,\removable) \stackrel{\text{df}}{=} \{r \in P \mid Head(r) = \bot \land \forall \text{lit } \in Body(r), \m_1 \models \text{lit } \vee \m_2 \models \text{lit }\}$
%     \item \addable contrastive explanation answers a query $Q$ if $\m_{alt} \models Q$
%     \item (abduction) Given two sets of facts: $Add$ and $Rm$. $P_{alt}$ is obtained by considering subsets $\addable \subseteq Add$ and $\removable \subseteq Rm$ such that: $P_{alt} = (P_{ref} \setminus \removable) \cup \addable$. $\addable = \removable  \rightarrow P_{alt} = P_{ref}$, that is, no abduction was needed (alternative explanation).
%     \begin{itemize}
%         \item \textbf{why} queries. When $\m_{ref} = \m_{alt}$ and $P_{ref} = P_{alt}$ ($\addable = \removable$ and possibly $\addable = \removable = \emptyset $) and $\lambda_{ref} = \lambda_{alt}$, the query is true in the reference model.
%         \item \textbf{whynot} contrastive (non counterfactual, alternative). When $P_{ref} = P_{alt}$ and $\m_{ref} \neq \m_{alt}$
%         \item \textbf{whynot} contrastive and counterfactual (hypothetical). When $P_{alt} \neq P_{ref}$ and $\m_{ref} \neq \m_{alt}$.
%     \end{itemize}
%     \item
%         IMPORTANT: constraints are only got from reference model.
%         Does it makes sense to add constraints in the hypothetical world?
%         Maybe to select hypothetical worlds. Like: in the query we could say "never abduce this and this".
%         But, never for explanation, as introducing constraints in $P_{alt}$ only prunes $P_{ref}$ models which never helps in satisfying queries.
% \end{itemize}

% \begin{definition}[Asplain's Contrastive Explanation]
%     Define a function that takes a Contrastive Explanation and
%     \begin{itemize}
%         \item Hides nodes (constraint nodes are always hidden)
%         \item Prunes edges.
%         \item \textbf{Enablers may now appear}
%     \end{itemize}
% \end{definition}

% \begin{definition}[Using only reachability]
%     \item Using the defined function
%     \item Reverse traverse the graph from the
% \end{definition}

% \subsection{Selecting the contrasted model}

% \begin{itemize}
%     \item Notice that the minimization we might impose is not subset minimal like for MUS.
%     The subset minimality can't be encoding in ASP directly.
%     \item We can think of this selection as explanation preferences that define the contrastive model.
%     This preference can be encoded in an ASP program.
%     At the moment this is very general, since we use any program\comment{TODO: how do we formalize this?}
%     \item We don't see so many papers talk about preferences on explanations.
%     In \cite{alhasawe24a}  there is the option to move up and down rules to prefer some more than others, but that is it. \comment{TODO: Check if this is really the case}

% \end{itemize}


% \subsubsection{Abducibles}


% \begin{itemize}
%     \item Things that will change from the reference model to the hypothetical one.
%     They can be either added or removed in the contrasted model.
%     \item The possible atoms to abduce are defined for each application.
%     \item There is a difference between abducing a predicate in the whole program,
%     which means that even if it comes from a rule, if it is abduced then it wont be generated,
%     vs an option where only the facts are abduced. This boils down to the question of abducing rules vs abducing facts.
%     \item What is abducible or not is defined by the \emph{explanation-preference} ASP program.
%     Depending on what is abducible we may be giving different types of explanations/answers.
%     For instance: in the case of an reasoning agent, it does not make sense to abduce thing that were observed, but only beliefs or possible actions.
%     Similar in the case of diagnosis.
%     For sudoku or configuration, it does makes sense to abduce the user's input.
% \end{itemize}

% \subsection{Implementation}\label{sec:approach:implementation}

% \begin{itemize}
%     \item We use several transformers to create new rules and add information. \comment{TODO: Perhaps part of this can be done with clingos reification?}
%     \item The intention is to also make this Transformers available for future explanation tasks. \comment{TODO: Where do we want to make this available? clingoexplaid?}
%     \item The explanation preference is encoded as an additional ASP encoding.
%     \item The contrastive graph is defined as a set of facts. Where attributes on edges and nodes give the contrastive semantics.
%     \item We give the full graph, although the relevant information for the query might be in just one part.
%     Creating a reduced reachable graph is possible, but we will try to leave this to the LLM.
%     \item Accepted language fragment \comment{TODO: Brais is adding count}
%     \item Facts defining the contrastive graph:


%         \begin{itemize}
%             \item \texttt{node(\addable)}: Defines a node in the graph
%             \begin{itemize}
%                 \item \textbf{\addable}: the node identifier (atom)
%             \end{itemize}
%             \item \texttt{edge(N,N',ID)}: Defines an edge in the graph. They represent the causal relationships between nodes, as well as negative relationships (inhibitors).
%             \begin{itemize}
%                 \item \textbf{N}: the origin node
%                 \item \textbf{N'}: the destination node
%                 \item \textbf{ID}: the identifier of the edge (Required for multi-edges)
%             \end{itemize}
%             \item \texttt{attr(T,N,\addable,V)}: Defines an attribute for a node or edge.
%             \begin{itemize}
%                 \item \textbf{T}: the type of the element (\texttt{node} or \texttt{edge})
%                 \item \textbf{N}: the node or edge identifier
%                 \item \textbf{\addable}: the attribute name
%                 \item \textbf{V}: the attribute value
%             \end{itemize}
%             \begin{itemize}
%                 \item \textbf{T=\texttt{node}}:
%                 \begin{itemize}
%                     \item \texttt{\addable=origin}: \texttt{V} = either \texttt{real} or \texttt{hypothetical}
%                     \item \texttt{\addable=abduced}: \texttt{V} = either \texttt{rm} or \texttt{add}
%                     \item \texttt{\addable=query}: \texttt{V} = either \texttt{include} or \texttt{exclude}
%                 \end{itemize}
%                 \item \textbf{T=\texttt{edge}}:
%                 \begin{itemize}
%                     \item \texttt{\addable=origin}: \texttt{V} = either \texttt{real} or \texttt{hypothetical}
%                     \item \texttt{\addable=type}: \texttt{V} = either \texttt{inhibitor} \texttt{reciprocal\_inhibitor} or \texttt{cause}
%                 \end{itemize}
%             \end{itemize}
%         \end{itemize}
% \end{itemize}

% \subsection{Interactivity}

% \begin{itemize}
%     \item We can integrate this system into an interactive setting where we make a difference between user selections and input.
%     \item In this case we can change the explanation preference encoding, to prefer abducing user input before the input for the problem.
%     For instance, in a sudoku, you would first say that in order to put a 1 in a cell you would have to change the 1 you put on that road,
%     rather than saying that there would have to have to change the 1 that was an initial input value somewhere else, which the user can't change themselve.
% \end{itemize}


% \subsection{LLM}

% \begin{itemize}
%     \item We use the LLM to interpret our graph into natural language.
%     \item Do we want to use also the LLM to generate the query atoms? Like in \cite{gekaoe24a}?
%     \item The only input for the LLM is the computed graph as facts.
%     \item The LLM could have a more structured output, like a JSON structure that gives more information.
%     For instance, the atoms that are relevant for the natural language explanation provided.
%     This would be useful in a system like clinguin to highlight sections of the UI.
% \end{itemize}


